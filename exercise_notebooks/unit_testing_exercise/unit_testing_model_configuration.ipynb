{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing ML Code: Hands-on Exercise (Configuration)\n",
    "\n",
    "## In this notebook we will explore unit tests for *model configuration*\n",
    "\n",
    "#### We will use a classic toy dataset: the Iris plants dataset, which comes included with scikit-learn\n",
    "Dataset details: https://scikit-learn.org/stable/datasets/index.html#iris-plants-dataset\n",
    "\n",
    "As we progress through the course, the complexity of examples will increase, but we will start with something basic. This notebook is designed so that it can be run in isolation, once the setup steps described below are complete. Cells should be run one after the other without skipping any.\n",
    "\n",
    "### Setup\n",
    "\n",
    "Let's begin by importing the dataset and the libraries we are going to use. Make sure you have run `pip install -r requirements.txt` on requirements file located in the same directory as this notebook. We recommend doing this in a separate virtual environment (see dedicated setup lecture).\n",
    "\n",
    "If you need a refresher on jupyter, pandas or numpy, there are some links to resources in the section notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Access the iris dataset from sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Load the iris data into a pandas dataframe. The `data` and `feature_names`\n",
    "# attributes of the dataset are added by default by sklearn. We use them to\n",
    "# specify the columns of our dataframes.\n",
    "iris_frame = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Create a \"target\" column in our dataframe, and set the values to the correct\n",
    "# classifications from the dataset.\n",
    "iris_frame['target'] = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the `SimplePipeline` from the Test Input Values notebook (same as first exercise, no changes here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SimplePipeline:\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        # Shorthand to specify that each value should start out as\n",
    "        # None when the class is instantiated.\n",
    "        self.X_train, self.X_test, self.y_train, self.Y_test = None, None, None, None\n",
    "        self.model = None\n",
    "        self.load_dataset()\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Load the dataset and perform train test split.\"\"\"\n",
    "        # fetch from sklearn\n",
    "        dataset = datasets.load_iris()\n",
    "        \n",
    "        # remove units ' (cm)' from variable names\n",
    "        self.feature_names = [fn[:-5] for fn in dataset.feature_names]\n",
    "        self.frame = pd.DataFrame(dataset.data, columns=self.feature_names)\n",
    "        self.frame['target'] = dataset.target\n",
    "        \n",
    "        # we divide the data set using the train_test_split function from sklearn, \n",
    "        # which takes as parameters, the dataframe with the predictor variables, \n",
    "        # then the target, then the percentage of data to assign to the test set, \n",
    "        # and finally the random_state to ensure reproducibility.\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.frame[self.feature_names], self.frame.target, test_size=0.65, random_state=42)\n",
    "        \n",
    "    def train(self, algorithm=LogisticRegression):\n",
    "        \n",
    "        # we set up a LogisticRegression classifier with default parameters\n",
    "        self.model = algorithm(solver='lbfgs', multi_class='auto')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        return self.model.predict(input_data)\n",
    "        \n",
    "    def get_accuracy(self):\n",
    "        \n",
    "        # use our X_test and y_test values generated when we used\n",
    "        # `train_test_split` to test accuracy.\n",
    "        # score is a method on the Logisitic Regression that \n",
    "        # returns the accuracy by default, but can be changed to other metrics, see: \n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score\n",
    "        return self.model.score(X=self.X_test, y=self.y_test)\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Helper method to run multiple pipeline methods with one call.\"\"\"\n",
    "        self.load_dataset()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the Pipeline\n",
    "\n",
    "We now create a new pipeline class which inherits from the `SimplePipeline` with one important modification: The configuration for the model is passed in as an argument when the pipeline object is instantiated. This means that configuration can be set via an external object or file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineWithConfig(SimplePipeline):\n",
    "    def __init__(self, config):\n",
    "        # Call the inherited SimplePipeline __init__ method first.\n",
    "        super().__init__()\n",
    "        # Pass in a config object which we use during the train method.\n",
    "        self.config = config\n",
    "            \n",
    "    def train(self, algorithm=LogisticRegression):\n",
    "        # note that we instantiate the LogisticRegression classifier \n",
    "        # with params from the pipeline config\n",
    "        self.model = algorithm(solver=self.config.get('solver'),\n",
    "                               multi_class=self.config.get('multi_class'))\n",
    "        self.model.fit(self.X_train, self.y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we Unit Test\n",
    "\n",
    "We will employ a simple unit test to check the configuration values.\n",
    "\n",
    "Let's say that after extensive testing in the research environment, we deduce that certain types of configuration (parameters passed to the model, preprocessing settings, GPU configurations etc.) are optimal, or that certain configurations tend to be a bad idea. We should then test our configuration is validated against this understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "\n",
    "# arbitrarily selected for demonstration purposes. In a real\n",
    "# system you would define this in config and import into your\n",
    "# tests so you didn't have to update config and tests when\n",
    "# the values changed.\n",
    "ENABLED_MODEL_SOLVERS = {'lbfgs', 'newton-cg'}\n",
    "\n",
    "\n",
    "class TestIrisConfig(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # We prepare the pipeline for use in the tests\n",
    "        config = {'solver': 'lbfgs', 'multi_class': 'auto'}\n",
    "        self.pipeline = PipelineWithConfig(config=config)\n",
    "        self.pipeline.run_pipeline()\n",
    "    \n",
    "    def test_pipeline_config(self):\n",
    "        # Given\n",
    "        # fetch model config using sklearn get_params()\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator.get_params\n",
    "        model_params = self.pipeline.model.get_params()\n",
    "        \n",
    "        # Then\n",
    "        self.assertTrue(model_params['solver'] in ENABLED_MODEL_SOLVERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.034s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestIrisConfig)\n",
    "unittest.TextTestRunner(verbosity=1, stream=sys.stderr).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration Testing: Hands-on Exercise\n",
    "Change the model config so that the test fails. Do you understand why the test is failing?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
